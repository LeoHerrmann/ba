Aus den im Rahmen dieser Arbeit durchgeführten Experimenten geht hervor, dass der in dieser Arbeit implementierte MCTS-Agent robuster hinsichtlich Unsicherheiten gegenüber Aktionen ist als der in dieser Arbeit implementierte PPO-Agent. Hinsichtlich Robustheit bezüglich Unsicherheiten gegenüber Beobachtungen konnte dies aufgrund von stochastisch bedingten Messungenauigkeiten bis zu einem gewissen Grad an Unsicherheit ebenfalls festgestellt werden. Aufgrund begrenzter Ressourcen war es nicht möglich, einen PPO-Agenten zu trainieren, der in der neutralen Umgebung ohne Unsicherheiten mit dem MCTS-Agenten mithalten kann. Es ist davon auszugehen, dass die kurzfristigere Strategie des PPO-Agenten anfälliger für die in den Szenarien zur Untersuchung von Robustheit eingeführten Unsicherheiten ist. Die Beobachtung, dass der MCTS-Agent robuster als der PPO-Agent ist, kann damit nicht auf die Verfahren MCTS und PPO und schon gar nicht auf symbolische Algorithmen und Reinforcement Learning verallgemeinert werden. Damit wurde nur ein Teilbereich der zu untersuchenden Frage beantwortet, inwiefern symbolische Algorithmen oder RL-Verfahren robuster sind.

Mit der in dieser Arbeit angewandten Methodik war es jedoch möglich, die Robustheit von zwei konkreten Implementierungen zu quantifizieren. Es ist naheliegend, dass auch weitere Teilbereiche der zu untersuchenden Frage beantwortet werden können, indem die Methodik auf weitere MDPs und entsprechenden Lösungsverfahren übertragen wird. Diese erfordert lediglich, dass das zu untersuchende MDP gezielt auf Aspekte von Robustheit modifiziert, die zu untersuchenden Lösungen auf das modifizierte MDP angewandt und der Verlust ihrer Leistungsfähigkeit untersucht wird.

Um die Frage zu beantworten, wie sich der Vergleich der Robustheit von MCTS und PPO bei Vier Gewinnt allgemein verhält, ist es notwendig, zwei Agenten zu untersuchen, die unter neutralen Bedingungen möglichst gleich stark sind. Für das Training eines stärkeren PPO-Agenten scheint die Trainingsstrategie von Zhong et al. in Kombination mit mit Faltungsmatritzen ausgestatteten neuronalen Netzwerken einen vielversprechenden Ansatz darzustellen. Um Aussagen über die Robustheit von MCTS und PPO über verschiedene Anwendungsfälle verallgemeinern zu können, sind Untersuchungen mit anderen Anwendungsfällen notwendig, die beispielsweise verschiedene Zustands- und Aktionsräume aufweisen oder die Möglichkeit bieten, physikalische Parameter der Problemumgebung zu variieren. Aussagen über den Vergleich von Robustheit zwischen symbolische Algorithmen und RL-Verfahren allgemein erfordern Untersuchungen mit ausreichend verschiedenen Verfahren und Anwendungsszenarien. Hierbei stellt sich jedoch die Frage, inwiefern dies aufgrund der Vielzahl von zu lösenden Problemen und entsprechenden Lösungsverfahren möglich oder überhaupt erstrebenswert ist.
